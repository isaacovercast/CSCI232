{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Python -- multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing as mp\n",
    "import requests\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel processing involves farming jobs out to different processors on your machine. All modern laptops have multiple processors that can be used to run tasks in parallel. However, writing parallel code can be tricky, and it often requires some understanding of how parallel processing works in order to write code to use it efficiently. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processor IDs\n",
    "The `pid` of a process is the processor ID. This is simply a number that is assigned to a process when it is started. You can think of a process as a reservation on one of your computer's CPUs. It is being reserved for a set task. When we run parallel code with 4 processes the work should be farmed out to four different `pids` that will run on different CPUs. Below is a very simple function that we will use just to check that our code is working the way that we expect. All this function does is tell `sleep` for 1 second, and then return the value of its `pid`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def who(i):\n",
    "    time.sleep(i)\n",
    "    return os.getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  (1) Run the who function on a single processor\n",
    "As expected, this takes about 1 second to complete, and return a number corresponding to the process it was run on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160801"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run single/normal function\n",
    "who(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  (2) Run the who function on multiple processors\n",
    "Here we will submit 10 jobs, one for each item in `queries`, and run the `who()` function on each. We would expect that on a single processor this should take at least 10 seconds to run if we use a 1 second sleep time, but because we're running it on 4 processors in parallel it should take less time. As you can see in the output, each of the four available processors runs a job (i.e., the same `pid` is returned several times). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[160825,\n",
       " 160826,\n",
       " 160827,\n",
       " 160828,\n",
       " 160826,\n",
       " 160827,\n",
       " 160825,\n",
       " 160828,\n",
       " 160826,\n",
       " 160828]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with ProcessPoolExecutor(max_workers=4) as pool:\n",
    "    \n",
    "    # submit queries to threads\n",
    "    jobs = [pool.submit(who, 1) for q in queries]\n",
    "    \n",
    "    # collect results\n",
    "    results = [i.result() for i in jobs]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProcessPool and Multiprocessing are very similar. \n",
    "These are two different syntaxes for doing multiprocessing. The former is new to Python3, the latter works in Py2 or Py3 and is more commonly used currently, so you are likely to find many more examples online of the MultiProcessing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.03 s ± 7.28 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 5\n",
    "with ProcessPoolExecutor(max_workers=4) as pool:\n",
    "    \n",
    "    # submit queries to threads\n",
    "    jobs = [pool.submit(who, 1) for q in queries]\n",
    "    \n",
    "    # collect results\n",
    "    results = [i.result() for i in jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.03 s ± 8.17 ms per loop (mean ± std. dev. of 5 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 5\n",
    "with mp.Pool(processes=4) as pool:\n",
    "    \n",
    "    # submit queries to threads (with args as tuples)\n",
    "    jobs = [pool.apply_async(who, [1]) for q in queries]\n",
    "    \n",
    "    # collect results\n",
    "    results = [i.get() for i in jobs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Pool` object\n",
    "In the example above we use a `with` context manager to create a `Pool` object. The object is what interfaces with your CPUs (processes) to send inputs and receive outputs of function calls. There are several ways to send and receive jobs, but the most simple and understandable is the method called `apply_async` for `multiprocessing`, or `submit` for ProcessPoolExecutor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160899, 160900, 160901, 160902]\n"
     ]
    }
   ],
   "source": [
    "# apply_async returns the result of a function call when requested, and \n",
    "# does not block you from continuing to execute code while it is running.\n",
    "# This is true parallel processing.\n",
    "with mp.Pool(processes=4) as pool:\n",
    "    a = pool.apply_async(who, [1])\n",
    "    b = pool.apply_async(who, [1])\n",
    "    c = pool.apply_async(who, [1])\n",
    "    d = pool.apply_async(who, [1])\n",
    "    print([i.get() for i in (a, b, c, d)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `AsyncResult` object\n",
    "The object that is return by an `apply_async()` function call is called an `AsyncResult`. This object is used to query the job that we sent to a different processor to ask whether it is finished yet, and to collect the results when it is done. The four main functions to call from \"async\" objects are `wait`, `get`, `ready` and `successful`. The first function, `wait`, tells the object to `block` until the job is finished, meaning you will no longer be able to run code while it is running. The `get` call is used to ask for a result. It will also `block` if you ask for a result and the job is not finished yet. The `ready` statement is useful because you can ask whether a job is ready yet and it does not `block` when you ask. And finally, the `successful` function will return whether the job completed or raised an error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of the `get()` and `wait()` functions.\n",
    "The `wait()` function is called inside of the `get()` function, `wait` is only used if you want to block anything else from happening, such as other jobs from being submitted, until the `get` function can be called, meaning that results can be returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job was submitted\n",
      "waiting for result...\n",
      "executing print statements in this notebook while waiting...\n",
      "job finished\n"
     ]
    }
   ],
   "source": [
    "# start a pool\n",
    "with mp.Pool(processes=4) as pool:\n",
    "\n",
    "    # this does NOT BLOCK and so the code below is executed while \n",
    "    # the async job is running on a different processor\n",
    "    asyncr = pool.apply_async(time.sleep, [2])\n",
    "    print('job was submitted')\n",
    "    print('waiting for result...')\n",
    "    print('executing print statements in this notebook while waiting...')\n",
    "\n",
    "    # collect result\n",
    "    asyncr.get()\n",
    "    print('job finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job was submitted\n",
      "job finished; this couldn't be printed until it was finished\n"
     ]
    }
   ],
   "source": [
    "# start a pool\n",
    "with mp.Pool(processes=4) as pool:\n",
    "\n",
    "    # this DOES BLOCK and so the code below is NOT executed \n",
    "    # while the async job is running on a different processor,\n",
    "    # but instead only executes after the job is finished.\n",
    "    asyncr = pool.apply_async(time.sleep, [2])\n",
    "    print('job was submitted')\n",
    "\n",
    "    asyncr.wait()\n",
    "\n",
    "    # collect result\n",
    "    asyncr.get()\n",
    "    print(\"job finished; this couldn't be printed until it was finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of the `ready()` and `successful()` functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<multiprocessing.pool.ApplyResult object at 0x7fd4b81ce9d0> had an error\n",
      "<multiprocessing.pool.ApplyResult object at 0x7fd4b81cee50> was successful\n"
     ]
    }
   ],
   "source": [
    "# start a pool\n",
    "with mp.Pool(processes=4) as pool:\n",
    "\n",
    "    # submit a job that will run successfully\n",
    "    async0 = pool.apply_async(who, [2])\n",
    "    \n",
    "    # submit a job that will fail\n",
    "    async1 = pool.apply_async(who, ['apple'])\n",
    "    \n",
    "    # join jobs into an iterable \n",
    "    jobs = [async0, async1]\n",
    "    \n",
    "    # iterate over async results and print result of succesful jobs\n",
    "    while 1:\n",
    "        for job in jobs:\n",
    "            # skip over the job for now if not ready yet\n",
    "            if job.ready():\n",
    "                if job.successful():\n",
    "                    print('{} was successful'.format(job))\n",
    "                else:\n",
    "                    print('{} had an error'.format(job))\n",
    "                # remove job from queue\n",
    "                jobs.remove(job)\n",
    "        \n",
    "        # end loop if all jobs are finished \n",
    "        time.sleep(0.5)\n",
    "        if len(jobs) == 0:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
