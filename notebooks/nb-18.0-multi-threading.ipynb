{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Python -- concurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `concurrent.futures` library can be used to submit parallel jobs running either on separate threads or processors. Because as we'll see next  in the next notebook the `multiprocessing` library has a different syntax for doing multiprocessing, this library is more commonly used for multithreading, i.e., running concurrent jobs on the same process. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import requests \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function to be parallelized\n",
    "We want to make a number of google searches. Here we use `requests` to make a query to google using the RESTful API URL string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsearch(query):\n",
    "    res = requests.get(\"http://google.com/search?q={}\".format(query))\n",
    "    return res.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time execution to perform five searches on 1 vs 4 threads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"dog\", \"cat\", \"mouse\", \"bird\", \"mushroom\",\n",
    "    \"weasel\", \"elephant\", \"rat\", \"tree\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.81 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    \n",
    "    # submit queries to threads\n",
    "    jobs = [executor.submit(gsearch, q) for q in queries]\n",
    "    \n",
    "    # collect results\n",
    "    results = [i.result() for i in jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.06 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "    \n",
    "    # submit queries to threads\n",
    "    jobs = [executor.submit(gsearch, q) for q in queries]\n",
    "    \n",
    "    # collect results\n",
    "    results = [i.result() for i in jobs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained\n",
    "The `with` context manager ensures that the ThreadPool is properly shutdown if the jobs are interrupted for any reason. By initiating a ThreadPoolExecutor object with some number of workers we can then start to send jobs to those workers. This is done using the `submit` function call, which returns an asynchronous result object. This object can be used to retrieve the result of the function once its finished. This is done by making the `result()` request later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.arange(1000000)\n",
    "b = np.arange(1000000)\n",
    "c = np.arange(1000000)\n",
    "d = np.arange(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Calculate the sum of all values in a,b,c and d.\n",
    "Use `timeit` to measure how long it takes to do this without parallel code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.92 ms ± 327 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.sum(a + b + c + d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculate the sum of all values in a,b,c and d\n",
    "Use `timeit` to measure how long it takes to do this *with* parallel code. Clue: call `executor.submit(np.sum, arr)` for each array, and then sum the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.83 ms ± 59.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    \n",
    "    # submit queries to threads\n",
    "    jobs = [executor.submit(np.sum, i) for i in (a, b, c, d)]\n",
    "    \n",
    "    # collect results\n",
    "    res = sum(i.result() for i in jobs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
